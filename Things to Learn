Things to Learn

1) Machine Learning
	- Wiki Machine Learning - https://en.wikipedia.org/wiki/Machine_learning
	- Supervised Learning 
		http://www.kdnuggets.com/2016/08/10-algorithms-machine-learning-engineers.html/2
		1. Decision Tree
			-  A decision tree is a decision support tool that uses a tree-like graph or model of decisions and their possible consequences, including chance-event outcomes, resource costs, and utility. Take a look at the image to get a sense of how it looks like.
		2. Naive Bayes Classification
			- Naïve Bayes Classification: Naïve Bayes classifiers are a family of simple probabilistic classifiers based on applying Bayes’ theorem with strong (naïve) independence assumptions between the features. The featured image is the equation — with P(A|B) is posterior probability, P(B|A) is likelihood, P(A) is class prior probability, and P(B) is predictor prior probability.
		3. Ordinary Least Square Regression 
			- Ordinary Least Squares Regression: If you know statistics, you probably have heard of linear regression before. Least squares is a method for performing linear regression. You can think of linear regression as the task of fitting a straight line through a set of points. There are multiple possible strategies to do this, and “ordinary least squares” strategy go like this — You can draw a line, and then for each of the data points, measure the vertical distance between the point and the line, and add these up; the fitted line would be the one where this sum of distances is as small as possible.
		4. Logistic Regression
			- Logistic Regression: Logistic regression is a powerful statistical way of modeling a binomial outcome with one or more explanatory variables. It measures the relationship between the categorical dependent variable and one or more independent variables by estimating probabilities using a logistic function, which is the cumulative logistic distribution.
		5. Support Vector Machine
			- Support Vector Machines: SVM is binary classification algorithm. Given a set of points of 2 types in N dimensional place, SVM generates a (N — 1) dimensional hyperlane to separate those points into 2 groups. Say you have some points of 2 types in a paper which are linearly separable. SVM will find a straight line which separates those points into 2 types and situated as far as possible from all those points.
		6. Ensemble
			-  Ensemble Methods: Ensemble methods are learning algorithms that construct a set of classifiers and then classify new data points by taking a weighted vote of their predictions. The original ensemble method is Bayesian averaging, but more recent algorithms include error-correcting output coding, bagging, and boosting.

		Unsupervised Learning

		7. Clustering Algorithms: Clustering is the task of grouping a set of objects such that objects in the same group (cluster) are more similar to each other than to those in other groups.

		8. Principal Component Analysis
		 Principal Component Analysis: PCA is a statistical procedure that uses an orthogonal transformation to convert a set of observations of possibly correlated variables into a set of values of linearly uncorrelated variables called principal components.

		9 Singular Value Decomposition
		Singular Value Decomposition: In linear algebra, SVD is a factorization of a real complex matrix. For a given m * n matrix M, there exists a decomposition such that M = UΣV, where U and V are unitary matrices and Σ is a diagonal matrix.


		- Classification
		- Regression
	- Clustering

	- Genetic Algorithm
	- Bayseian Networks


2) Deep Learning
	- TensorFlow
	- OpenAI Gym
	- OpenNN

3) Natural Language Understanding (NLU)
	- CoreNLP (Stanford)
	http://stanfordnlp.github.io/CoreNLP/

4) Graphics
 	- OpenGL
 	- Qt

5) RTOS
	- FreeRTOS
	- QNX
	- Linux RT

6) Distributed Systems
 	- Hadoop
 	- Hive
 	- PrestoDB
 	- AWS
